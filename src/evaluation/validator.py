import torch
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report
import numpy as np
import pandas as pd
import pathlib

def validate_nn(model, data_loader):
    """
    Validate a neural network model using a DataLoader.

    The model's performance is evaluated using accuracy, ROC-AUC score, and a full classification report,
    which includes precision, recall, f1-score, and support for each class.

    Parameters:
        model: torch.nn.Module
            The neural network model to validate.
        data_loader: torch.utils.data.DataLoader
            DataLoader containing the dataset for validation.

    Returns:
        accuracy: float
            The accuracy of the model on the validation set.
        roc_auc: float
            The ROC-AUC score of the model on the validation set.
        classification_rep: str
            A text report showing the main classification metrics.
    """
    model.eval()  # Set the model to evaluation mode
    predictions = []
    probabilities = []
    true_labels = []

    with torch.no_grad():
        for X_batch, y_batch in data_loader:
            outputs = model(X_batch)
            # Assuming binary classification with a single output neuron
            predicted_probs = outputs.cpu().numpy()
            predicted_labels = (predicted_probs > 0.5).astype(np.int32)
            predictions.extend(predicted_labels)
            probabilities.extend(predicted_probs)
            true_labels.extend(y_batch.cpu().numpy())

    # Calculate metrics
    accuracy = accuracy_score(true_labels, predictions)
    roc_auc = roc_auc_score(true_labels, probabilities)
    classification_rep = classification_report(true_labels, predictions, target_names=['Class 0', 'Class 1'])

    print(f"Accuracy: {accuracy:.4f}")
    print(f"ROC-AUC: {roc_auc:.4f}")
    print("Classification Report:")
    print(classification_rep)
    
    # export accuracy, roc_auc, classification_rep to single csv
    export_path = "reports/neural_network_metrics.csv"
    pathlib.Path(export_path).parent.mkdir(parents=True, exist_ok=True)
    export_metrics_to_csv(accuracy, roc_auc, classification_rep, export_path)
    return accuracy, roc_auc, classification_rep

def validate_gbm(model, X_test, y_test):
    """
    Validate a gradient boosting model using the full test dataset.

    Similarly to the neural network validation, this function computes the accuracy, ROC-AUC score,
    and classification report for the gradient boosting model's predictions.

    Parameters:
        model: A gradient boosting model, like XGBClassifier
            The gradient boosting model to validate.
        X_test: array-like of shape (n_samples, n_features)
            Test features.
        y_test: array-like of shape (n_samples,)
            True labels for test data.

    Returns:
        accuracy: float
            The accuracy of the model on the test set.
        roc_auc: float
            The ROC-AUC score of the model on the test set.
        classification_rep: str
            A text report showing the main classification metrics.
    """
    # Gradient boosting models typically provide predict_proba for classification
    probabilities = model.predict_proba(X_test)[:, 1]
    predictions = (probabilities > 0.5).astype(int)

    # Calculate metrics
    accuracy = accuracy_score(y_test, predictions)
    roc_auc = roc_auc_score(y_test, probabilities)
    classification_rep = classification_report(y_test, predictions, target_names=['Class 0', 'Class 1'])

    print(f"Accuracy: {accuracy:.4f}")
    print(f"ROC-AUC: {roc_auc:.4f}")
    print("Classification Report:")
    print(classification_rep)
    export_path = "reports/gradient_boosting_metrics.csv"
    pathlib.Path(export_path).parent.mkdir(parents=True, exist_ok=True)
    export_metrics_to_csv(accuracy, roc_auc, classification_rep, export_path)
    return accuracy, roc_auc, classification_rep

def export_metrics_to_csv(accuracy, roc_auc, classification_rep, export_path):
    """
    Export accuracy, ROC-AUC, and classification report to a single CSV file.
    This is rough implementation, but it works.
    
    Parameters:
        accuracy: float
            The accuracy score of the model.
        roc_auc: float
            The ROC-AUC score of the model.
        classification_rep: str
            The classification report generated by sklearn.metrics.classification_report.
        export_path: str
            The file path to export the CSV to.
    """
    # Parse the classification report for export
    report_df = pd.DataFrame([classification_rep]).transpose().reset_index()
    
    # Create a DataFrame for the metrics
    metrics_df = pd.DataFrame({
        "Metric": ["Accuracy", "ROC-AUC"],
        "Score": [accuracy, roc_auc]
    })

    # Concatenate the metrics DataFrame with the classification report DataFrame
    final_df = pd.concat([metrics_df, report_df], ignore_index=True)

    # Export to CSV
    final_df.to_csv(export_path, index=False)
